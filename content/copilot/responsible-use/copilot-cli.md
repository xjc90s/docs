---
title: Responsible use of GitHub Copilot CLI
shortTitle: Copilot CLI
intro: 'Learn how to use {% data variables.copilot.copilot_cli %} responsibly by understanding its purposes, capabilities, and limitations.'
product: '{% data reusables.gated-features.copilot-cli %}'
versions:
  feature: copilot
redirect_from:
  - /copilot/github-copilot-in-the-cli/about-github-copilot-in-the-cli
  - /copilot/responsible-use-of-github-copilot-features/responsible-use-of-github-copilot-in-the-cli
  - /copilot/responsible-use-of-github-copilot-features/copilot-in-the-cli
  - /copilot/responsible-use/copilot-in-the-cli
contentType: rai
category:
  - Responsible use
  - Learn about Copilot CLI
---

## About {% data variables.copilot.copilot_cli %}

{% data variables.copilot.copilot_cli %} provides a chat-like interface in the terminal that can autonomously create and modify files on your computer and execute commands. You can ask {% data variables.product.prodname_copilot_short %} to perform any action on the files in the active directory.

{% data variables.copilot.copilot_cli %} can generate tailored changes based on your description and configurations, including tasks like bug fixes, implementing incremental new features, prototyping, documentation, and codebase maintenance.

While working on your task, the {% data variables.product.prodname_copilot_short %} agent has access to your local terminal environment where it can make changes to your code, execute automated tests, run linters, and execute commands available in your environment.

The agent has been evaluated across a variety of programming languages, with English as the primary supported language.

The agent works by using a combination of natural language processing and machine learning to understand your task and make changes in a codebase to complete the task. This process can be broken down into a number of steps.

### Input processing

Your input is combined with relevant contextual information to form a prompt. That prompt is sent to a large language model for processing. Inputs can take the form of plain natural language, code snippets, or references to files in your terminal.

### Language model analysis

The prompt is then passed through a large language model, which is a neural network that has been trained on a large body of data. The language model analyzes the input prompt to help the agent reason about the task and use the necessary tools.

### Response generation

The language model generates a response based on its analysis of the prompt. This response can take the form of natural language suggestions, code suggestions, file modifications, and command executions.

### Output formatting

The response generated by the agent is formatted and presented to you. {% data variables.copilot.copilot_cli %} uses syntax highlighting, indentation, and other formatting features to add clarity to the generated response.

The agent might also want to execute commands in your local environment and create, edit, or delete files in your file system in order to complete your task.

You may provide feedback to the agent after it returns a response in the interactive chat window. The agent will then resubmit that feedback to the language model for further analysis. Once the agent completes changes based on feedback, the agent will return an additional response.

Copilot is intended to provide you with the most relevant solution for task resolution. However, it may not always provide the answer you are looking for. You are responsible for reviewing and validating responses generated by {% data variables.product.prodname_copilot_short %} to ensure they are accurate and appropriate. For more information, see the section [Improving the results from {% data variables.copilot.copilot_cli %}](#improving-the-results-from-github-copilot-cli), later in this article.

## Use cases for {% data variables.copilot.copilot_cli %}

You can delegate a task to {% data variables.product.prodname_copilot_short %} in a variety of scenarios, including, but not limited to:

* **Codebase maintenance:** Tackling security-related fixes, dependency upgrades, and targeted refactoring.
* **Documentation:** Updating and creating new documentation.
* **Feature development:** Implementing incremental feature requests.
* **Improving test coverage:** Developing additional test suites for quality management.
* **Prototyping new projects:** Greenfielding new concepts.
* **Setting up your environment:** Running commands in your terminal to set up your local environment to work on existing projects
* **Find the right command to perform a task:** {% data variables.product.prodname_copilot_short %} can provide suggestions for commands to perform tasks you're trying to complete.
* **Explain an unfamiliar command:** {% data variables.product.prodname_copilot_short %} can provide a natural language description of a command's functionality and purpose.

## Improving the results from {% data variables.copilot.copilot_cli %}

{% data variables.copilot.copilot_cli %} can support a wide range of tasks. To enhance the responses you receive, and address some of the limitations of the agent, there are various measures that you can adopt.

For more information about limitations, see the section [Limitations of {% data variables.copilot.copilot_cli %}](#limitations-of-github-copilot-cli), later in this article.

### Ensure your tasks are well-scoped

{% data variables.copilot.copilot_cli %} leverages your prompt as key context when completing a task. The clearer and more well-scoped the prompt you provide, the better the results you will get. An ideal prompt includes:

* A clear description of the problem to be solved or the work required.
* Complete acceptance criteria on what a good solution looks like (for example, should there be unit tests?).
* Hints or pointers on what files need to be changed.

### Customize your experience with additional context

{% data variables.copilot.copilot_cli %} leverages your prompt and the repository’s code as context when generating suggested changes. To enhance {% data variables.product.prodname_copilot_short %}’s performance, consider implementing custom {% data variables.product.prodname_copilot_short %} instructions to help the agent better understand your project and how to build, test and validate its changes. For more information, see [AUTOTITLE](/copilot/how-tos/copilot-cli/customize-copilot/add-custom-instructions).

### Use {% data variables.copilot.copilot_cli %} as a tool, not a replacement

While {% data variables.copilot.copilot_cli %} can be a powerful tool for generating code and documentation, it is important to use it as a tool, rather than a replacement for human programming. You should always review and verify commands generated by {% data variables.copilot.copilot_cli %} to ensure that it meets your requirements and is free of errors or security concerns.

### Use secure coding and code review practices

Although {% data variables.copilot.copilot_cli %} can generate syntactically correct code, it may not always be secure. You should always follow best practices for secure coding, such as avoiding hard-coded passwords or SQL injection vulnerabilities, as well as following code review best practices, to address the agent’s limitations. You should always take the same precautions as you would with any code you write that uses material you did not independently originate, including precautions to ensure its suitability. These include rigorous testing, IP scanning, and checking for security vulnerabilities.

### Provide feedback

If you encounter any issues or limitations with {% data variables.copilot.copilot_cli %}, we recommend that you provide feedback using the `/feedback` command.

## Security measures for {% data variables.copilot.copilot_cli %}

### Constraining {% data variables.product.prodname_copilot_short %}’s permissions

By default, {% data variables.copilot.copilot_cli_short %}:

* Only has access to files and folders in, and below, the directory from which {% data variables.copilot.copilot_cli %} was invoked. Ensure you trust the files in this directory. If {% data variables.product.prodname_copilot_short %} wishes to access files outside the current directory, it will ask for permission. Only grant it permission if you trust the contents of that directory.
* Will ask for permission before modifying files. Ensure that it is modifying the correct files before granting permission.
* Will ask for permission before executing commands that may be dangerous. Review these commands carefully before giving it permission to run.

You can grant {% data variables.copilot.copilot_cli_short %} specific permissions, or all permissions, by using the various command line options: for example, `--allow-tool [TOOLS...]`, `--allow-all-tools`, `--allow-all` (or its slash command equivalent `/allow-all` for use in an interactive session). For more information, see [AUTOTITLE](/copilot/reference/cli-command-reference#command-line-options). Typically, when you use {% data variables.copilot.copilot_cli_short %} in autopilot mode, you will grant it full permissions to allow it to complete a task autonomously, without requiring you to approve activity as it works on the task. For more information, see [AUTOTITLE](/copilot/concepts/agents/copilot-cli/autopilot).

For more information about security practices while using {% data variables.copilot.copilot_cli %}, see "Security considerations" in [AUTOTITLE](/copilot/concepts/agents/about-copilot-cli#security-considerations).

## Limitations of {% data variables.copilot.copilot_cli %}

Depending on factors such as your codebase and input data, you may experience different levels of performance when using {% data variables.copilot.copilot_cli %}. The following information is designed to help you understand system limitations and key concepts about performance as they apply to {% data variables.copilot.copilot_cli %}.

### Limited scope

The language model used by {% data variables.copilot.copilot_cli %} has been trained on a large body of code but still has a limited scope and may not be able to handle certain code structures or obscure programming languages. For each language, the quality of suggestions you receive may depend on the volume and diversity of training data for that language.

### Potential biases

The language model used by {% data variables.copilot.copilot_cli %}’s training data and context gathered by the large language model may contain biases and errors that can be perpetuated by the tool. Additionally, {% data variables.copilot.copilot_cli %} may be biased towards certain programming languages or coding styles, which can lead to suboptimal or incomplete suggestions.

### Security risks

{% data variables.copilot.copilot_cli %} generates code and natural language based on the context of an issue or comment within a repository, which can potentially expose sensitive information or vulnerabilities if not used carefully. You should be careful to review all outputs generated by {% data variables.copilot.copilot_cli %} thoroughly prior to merging.

### Inaccurate code

{% data variables.copilot.copilot_cli %} may generate code that appears to be valid but may not actually be semantically or syntactically correct or may not accurately reflect the intent of the developer.

To mitigate the risk of inaccurate code, you should carefully review and test the generated code, particularly when dealing with critical or sensitive applications. You should also ensure that the generated code adheres to best practices and design patterns and fits within the overall architecture and style of the codebase.

### Public code

{% data variables.copilot.copilot_cli %} may generate code that is a match or near match of publicly available code, even if the "Suggestions matching public code" policy is set to "Block." See [AUTOTITLE](/copilot/managing-copilot/managing-copilot-as-an-individual-subscriber/managing-your-copilot-plan/managing-copilot-policies-as-an-individual-subscriber#enabling-or-disabling-suggestions-matching-public-code).

### Legal and regulatory considerations

Users need to evaluate potential specific legal and regulatory obligations when using any AI services and solutions, which may not be appropriate for use in every industry or scenario. Additionally, AI services or solutions are not designed for and may not be used in ways prohibited in applicable terms of service and relevant codes of conduct.

### Risk management and user accountability in command execution

Additional caution is required when asking or allowing {% data variables.copilot.copilot_cli %} to execute a command, particularly regarding the potential destructiveness of some suggested commands. You may encounter commands for file deletion or hard drive formatting, which can cause problems if used incorrectly. While such commands may be necessary in certain scenarios, you need to be careful when accepting and running these commands.

Additionally, you are ultimately responsible for the commands executed by {% data variables.copilot.copilot_cli %}. It is entirely your decision whether to use commands generated by {% data variables.copilot.copilot_cli %}. Despite the presence of fail-safes and safety mechanisms, you must understand that executing commands carries inherent risks. {% data variables.copilot.copilot_cli %} provides a powerful tool set, but you should approach its recommendations with caution and ensure that commands align with your intentions and requirements.

## Further reading

* [AUTOTITLE](/free-pro-team@latest/site-policy/github-terms/github-terms-for-additional-products-and-features#github-copilot)
* [{% data variables.product.prodname_copilot %} Trust Center](https://copilot.github.trust.page/)
